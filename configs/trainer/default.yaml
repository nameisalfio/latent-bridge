# --- Hardware & Reproducibility ---
accelerator: "auto"
precision: 32
deterministic: True
seed: 42

# --- Training Schedule ---
max_epochs: 50
eval_period: 1                    # How often to run full validation (every N epochs)
log_every_n_steps: 10             # How often to log scalars to wandb/console

# --- Solver (Optimizer & Loss) ---
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 1e-5
  betas: [0.9, 0.999]

criterion:
  _target_: torch.nn.CrossEntropyLoss

# --- Checkpointing & Persistence ---
checkpoint_period: 5              # Save a checkpoint every N epochs
checkpoint_dir: "checkpoints"     # Root directory for artifacts
resume_from_checkpoint: null      # Optional: path/to/model.pt
save_top_k: 1                     # Reference for logic growth (e.g., best.pt)

# --- Logging & Experiment Tracking ---
use_wandb: True
no_wandb: False                   # Added for easy CLI override: trainer.no_wandb=True
wandb_run_name: null              # Optional: custom name for the run